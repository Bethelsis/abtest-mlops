{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis testing: The classical p-value based algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis states that there is no difference in brand awareness between the exposed and control groups in the current case.  The level of significance is set at 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the z-test to calculate the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import statsmodels.stats.api as sms\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from math import ceil\n",
    "%matplotlib inline\n",
    "\n",
    "from statsmodels.stats.proportion import proportions_ztest,proportion_confint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the sample size\n",
    "\n",
    "The sample size is estimated using Power Analysis. This depends on the power of the test,the alpha value and the effect size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_size=sms.proportion_effectsize(0.20,0.25)\n",
    "required_n=sms.NormalIndPower().solve_power(\n",
    "    effect_size,\n",
    "    power=0.8,\n",
    "    alpha=0.05,\n",
    "    ratio=1)\n",
    "required_n=ceil(required_n)\n",
    "required_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random sampling from the dataset to abtain a sample size of 1092\n",
    "control_sample=df[df['experiment']=='control'].sample(n=required_n, random_state=22)\n",
    "exposed_sample=df[df['experiment']=='exposed'].sample(n=required_n, random_state=22)\n",
    "\n",
    "ab_test=pd.concat([control_sample,exposed_sample],axis=0)\n",
    "ab_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#calculating the sample size\n",
    "def sample(N,cl,e,p):\n",
    "    #calculate the z-score\n",
    "    z=stats.norm.ppf(1-(1-cl)/2)\n",
    "    #calculate n_0 value\n",
    "    n_0=z**2*p*(1-p)/e**2\n",
    "    #calculate n\n",
    "    n=n_0/(1+(n_0-1)/N)\n",
    "    #rounding up\n",
    "    n=ceil(n)\n",
    "    return n\n",
    "sample_size=sample(8076,0.95,0.05,0.5)\n",
    "sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_rates=ab_test.groupby('experiment')['response']\n",
    "#standard deviation of the proportion\n",
    "std_p=lambda x: np.std(x,ddof=0)\n",
    "#standard error of the proportion\n",
    "se_p=lambda x:stats.sem(x,ddof=0)\n",
    "\n",
    "conversion_rates=conversion_rates.agg([np.mean,std_p,se_p])\n",
    "conversion_rates.columns=['conversion_rate','std_deviation','std_error']\n",
    "conversion_rates.style.format('{:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_results=ab_test[ab_test['experiment']=='control']['response']\n",
    "exposed_results=ab_test[ab_test['experiment']=='exposed']['response']\n",
    "\n",
    "n_con=control_results.count()\n",
    "n_exp=exposed_results.count()\n",
    "successes=[control_results.sum(),exposed_results.sum()]\n",
    "nobs=[n_con, n_exp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_stat,pval=proportions_ztest(successes,nobs=nobs)\n",
    "z_stat,pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the obtained  p-value is 0.043 , which is lower than the alpha of 0.05, the null hypothesis is rejected .\n",
    "This means that there is a significant difference between the control group and the exposed group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential A/B Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "#REFERENCE\n",
    "# A Conditional Sequential Test for the Equality of Two Binomial Proportions\n",
    "# William Q. Meeker, Jr\n",
    "# Journal of the Royal Statistical Society. Series C (Applied Statistics)\n",
    "# Vol. 30, No. 2 (1981), pp. 109-115\n",
    "def ConditionalSPRT(self,x,y,t1,alpha=0.05,beta=0.10,stop=None):\n",
    "        if t1<=1:\n",
    "            printLog('warning',\"Odd ratio should exceed 1.\")\n",
    "        if (alpha >0.5) | (beta >0.5):\n",
    "            printLog('warning',\"Unrealistic values of alpha or beta were passed.\"\n",
    "                     +\" You should have good reason to use large alpha & beta values\")\n",
    "        if stop!=None:\n",
    "            stop=math.floor(n0)\n",
    "\n",
    "        def comb(n, k):\n",
    "            return factorial(n) // factorial(k) // factorial(n - k)\n",
    "        \n",
    "        def lchoose(b, j):\n",
    "            a=[]\n",
    "            if (type(j) is list) | (isinstance(j,np.ndarray)==True):\n",
    "                if len(j)<2:\n",
    "                    j=j[0]\n",
    "            if (type(j) is list) | (isinstance(j,np.ndarray)==True):\n",
    "                for k in j:\n",
    "                    n=b\n",
    "                    if (0 <= k) & (k<= n):\n",
    "                        a.append(math.log(comb(n,k)))\n",
    "                    else:\n",
    "                        a.append(0)\n",
    "            else:\n",
    "                n=b\n",
    "                k=j\n",
    "                if (0 <= k) & (k<= n):\n",
    "                    a.append(math.log(comb(n,k)))\n",
    "                else:\n",
    "                    a.append(0)\n",
    "\n",
    "            return np.array(a)\n",
    "\n",
    "        def g(x,r,n,t1,t0=1):\n",
    "            return -math.log(h(x,r,n,t1))+math.log(h(x,r,n,t0))\n",
    "\n",
    "        def h(x,r,n,t=1):\n",
    "            return f(r,n,t,offset=ftermlog(x,r,n,t))\n",
    "\n",
    "        def f(r,n,t,offset=0):\n",
    "            upper=max(0,r-n)\n",
    "            lower=min(n,r)\n",
    "            rng=list(range(upper,lower+1))\n",
    "            return np.sum(fterm(rng,r,n,t,offset))\n",
    "\n",
    "        def fterm(j,r,n,t,offset=0):\n",
    "            ftlog=ftermlog(j,r,n,t,offset)\n",
    "            return np.array([math.exp(ex) for ex in ftlog])\n",
    "\n",
    "        def ftermlog(j,r,n,t,offset=0):\n",
    "            xx=r-j\n",
    "            lch=lchoose(n,j)\n",
    "            lchdiff=lchoose(n,xx)\n",
    "            lg=np.array(j)*math.log(t)\n",
    "            lgsum=lch+lchdiff\n",
    "            lgsum2=lgsum+lg\n",
    "            lgdiff=lgsum2-offset\n",
    "\n",
    "            return lgdiff\n",
    "\n",
    "        def logf(r,n,t,offset=0):\n",
    "\n",
    "            z=f(r,n,t,offset)\n",
    "            if z>0:\n",
    "                return math.log(z)\n",
    "            else:\n",
    "                return np.nan\n",
    "\n",
    "        def clowerUpper(r,n,t1c,t0=1,alpha=0.05,beta=0.10):\n",
    "            offset=ftermlog(math.ceil(r/2),r,n,t1c)\n",
    "            z=logf(r,n,t1c,logf(r,n,t0,offset)+offset)\n",
    "            a=-math.log(alpha/(1-beta))\n",
    "            b=math.log(beta/(1-alpha))\n",
    "            lower=b\n",
    "            upper=1+a\n",
    "            return (np.array([lower,upper])+z)/math.log(t1c/t0)\n",
    "            \n",
    "        l=math.log(beta/(1-alpha))\n",
    "        u=-math.log(alpha/(1-beta))\n",
    "        sample_size=min(len(x),len(y))\n",
    "        n=np.array(range(1,sample_size+1))\n",
    "\n",
    "        if stop!=None:\n",
    "            n=np.array([z for z in n if z<=stop])\n",
    "        x1=np.cumsum(x[n-1])\n",
    "        r=x1+np.cumsum(y[n-1])\n",
    "        stats=np.array(list(map(g,x1, r, n, [t1]*len(x1)))) #recurcively calls g\n",
    "\n",
    "        clu=list(map(clowerUpper,r,n,[t1]*len(r),[1]*len(r),[alpha]*len(r), [beta]*len(r)))\n",
    "        limits=[]\n",
    "        for v in clu:\n",
    "            inArray=[]\n",
    "            for vin in v:\n",
    "                inArray.append(math.floor(vin))\n",
    "            limits.append(np.array(inArray))\n",
    "        limits=np.array(limits)\n",
    "\n",
    "        k=np.where((stats>=u) | (stats<=l))\n",
    "        cvalues=stats[k]\n",
    "        if cvalues.shape[0]<1:\n",
    "            k= np.nan\n",
    "            outcome='Unable to conclude.Needs more sample.'\n",
    "        else:\n",
    "            k=np.min(k)\n",
    "            if stats[k]>=u:\n",
    "                outcome=f'Exposed group produced a statistically significant increase.'\n",
    "            else:\n",
    "                outcome='Their is no statistically significant difference between two test groups'\n",
    "        if (stop!=None) & (k==np.nan):\n",
    "            c1=clowerUpper(r,stop,t1,alpha,beta)\n",
    "            c1=math.floor(np.mean(c1)-0.5)\n",
    "            if x1[n0]<=c1:\n",
    "                truncate_decision='h0'\n",
    "                outcome='Maximum Limit Decision. The aproximate decision point shows their is no statistically significant difference between two test groups'\n",
    "            else:\n",
    "                truncate_decision='h1'\n",
    "                outcome=f'Maximum Limit Decision. The aproximate decision point shows exposed group produced a statistically significant increase.'\n",
    "            truncated=stop\n",
    "        else:\n",
    "            truncate_decision='Non'\n",
    "            truncated=np.nan\n",
    "        return (outcome,n, k,l,u,truncated,truncate_decision,x1,r,stats,limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here. include other necessary functions as you want.\n",
    "class SequentialTest:\n",
    "    def __init__(self,exposed,control):\n",
    "        '''\n",
    "    initialise startup variables\n",
    "    '''\n",
    "\n",
    "  \n",
    "    def stoppingRule(self):\n",
    "        '''\n",
    "    This function should take current observation and return statistical decision made. \n",
    "    Consider truncate rule for longer tests\n",
    "    '''\n",
    "    S, a, b,\n",
    "\n",
    "    def computeBoundaries(self):\n",
    "        '''\n",
    "    This function shoud compute boundaries \n",
    "    '''\n",
    "\n",
    "    def plotTest(self):\n",
    "        '''\n",
    "    showing the cumulative statistical test (e.g., log probability ratio) and the uper and lower limits.\n",
    "    '''\n",
    "\n",
    "    def plotBoundaries(self):\n",
    "        '''cumulative sums of exposed successes, bounded by the critical limits.\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df):\n",
    "  '''\n",
    "  segment data into exposed and control groups\n",
    "  consider that SmartAd runs the experment hourly, group data into hours. \n",
    "      Hint: create new column to hold date+hour and use df.column.map(lambda x:  pd.Timestamp(x,tz=None).strftime('%Y-%m-%d:%H'))\n",
    "  create two dataframes with bernouli series 1 for posetive(yes) and 0 for negative(no)\n",
    "    Hint: Given engagement(sum of yes and no until current observation as an array) and success (yes countas an array), the method generates random binomial distribution\n",
    "        #Example\n",
    "           engagement = np.array([5, 3, 3])\n",
    "           yes = np.array([2, 0, 3])       \n",
    "         Output is \"[1] 1 0 1 0 0 0 0 0 1 1 1\", showing a binary array of 5+3+3 values\n",
    "         of which 2 of the first 5 are ones, 0 of the next 3 are ones, and all 3 of\n",
    "         the last 3 are ones where position the ones is randomly distributed within each group.\n",
    "  '''\n",
    "  return exposed,control\n",
    "\n",
    "def plotDataSummary(exposed, control):\n",
    "      'This function plots cummulated success'\n",
    "\n",
    "def pretyPrintTestResult(self, test):\n",
    "      '''This function print final test result. Json format is recommended. For example\n",
    "  {\n",
    "    \"name\": \"\",\n",
    "    \"engagementCountControl\": ,\n",
    "    \"engagementCountExposed\": ,\n",
    "    \"positiveCountControl\": ,\n",
    "    \"positiveCountExposed\": ,\n",
    "    \"ControlSuccessProbability\": ,\n",
    "    \"ExposedSuccessProbability\": ,\n",
    "    \"basePositiveRate\": ,\n",
    "    \"significanceSign\": \".\",\n",
    "    \"lift\": ,\n",
    "    \"oddRatio\": ,\n",
    "    \"exactSuccessOddRate\":,\n",
    "    \"confidenceIntervalLevel\": ,\n",
    "    \"alpha\": ,\n",
    "    \"beta\": ,\n",
    "    \"power\": ,\n",
    "    \"criticalValue\": ,\n",
    "    \"lower critical(a)\": \n",
    "    \"upper critical(b)\": ,\n",
    "    \"TotalObservation\": \n",
    "  }'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "'Define statistical parameters such as alpha, beta, sample size if evan approach is used, odd ratio for SPRT'\n",
    "alpha=\n",
    "beta=\n",
    "#other variables here\n",
    "'Compute statistical lower and upper decision points such as a and b'\n",
    "a=\n",
    "b=\n",
    "#other variables here\n",
    "\n",
    "##data processing here\n",
    "exposed,control=transform_data(data)\n",
    "##plot data summary\n",
    "plotDataSummary(exposed,control)\n",
    "\n",
    "'Perform test. Loop over each of data entry and perform test. Accumulate result into dataframe and print out test journey'\n",
    "test=SequentialTest(...)\n",
    "\n",
    "'Print test result.'\n",
    "pretyPrintTestResult(resultObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
